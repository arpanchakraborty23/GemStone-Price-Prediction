{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\gemstone\\\\NoteBooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\gemstone'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.utils import read_yaml,create_dir,save_obj\n",
    "from src.constant.ymal_path import *\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    dir: Path\n",
    "    train_data: Path\n",
    "    test_data: Path\n",
    "    preproecss_obj: Path\n",
    "    target_col:str\n",
    "    train_arr:Path\n",
    "    test_arr: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigManager:\n",
    "    def __init__(self,\n",
    "                    config_filr_path=Config_ymal_file_path,\n",
    "                    prams_file_path=Param_ymal_file_path,\n",
    "                    scheema_file_path=Schema_ymal_file_path):\n",
    "            self.config=read_yaml(config_filr_path)\n",
    "            self.params=read_yaml(prams_file_path)\n",
    "            self.schema=read_yaml(scheema_file_path)\n",
    "\n",
    "            create_dir([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self):\n",
    "          config=self.config.data_transformation\n",
    "          schema=self.schema.TARGET_COLUMN\n",
    "\n",
    "          create_dir([config.dir])\n",
    "\n",
    "          data_transformation_config=DataTransformationConfig(\n",
    "                dir=config.dir,\n",
    "                train_data=config.train_data,\n",
    "                test_data=config.test_data,\n",
    "                preproecss_obj=config.preproecss_obj,\n",
    "                target_col=schema.name,\n",
    "                train_arr=config.train_arr,\n",
    "                test_arr=config.test_arr\n",
    "          )\n",
    "          return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logging.logger import logging\n",
    "from src.exception.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self,config:DataTransformationConfig) -> None:\n",
    "        self.config=config\n",
    "       \n",
    "\n",
    "    def get_data_transformation_obj(self):\n",
    "        try:\n",
    "            num_cols=['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "            catagorical_cols=['cut', 'color', 'clarity']\n",
    "\n",
    "            color_labels=['D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "            cut_labels=['Fair', 'Good', 'Very Good','Premium','Ideal']\n",
    "            clarity_labels=['I1','SI2','SI1','VS2','VS1','VVS2','VVS1','IF']\n",
    "\n",
    "            logging.info('Pipeline creation started')\n",
    "\n",
    "            num_cols_pipline=Pipeline(\n",
    "                steps=[\n",
    "                    ('IMPUTE',SimpleImputer(strategy='median')),\n",
    "                    ('SCALING',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            catagorical_cols_pipline=Pipeline(\n",
    "                steps=[\n",
    "                    ('ODINAL ENCODING',OrdinalEncoder(categories=[cut_labels,color_labels,clarity_labels])),\n",
    "                    ('IMPUTE',SimpleImputer(strategy='most_frequent')),\n",
    "                    ('SCALING',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info('pipline created')\n",
    "            preprocesser_obj=ColumnTransformer(\n",
    "                [\n",
    "                    ('num_cols',num_cols_pipline,num_cols),\n",
    "                    ('categorical_cols',catagorical_cols_pipline,catagorical_cols)\n",
    "                ]\n",
    "            )\n",
    "            logging.info(f'preprocesser object competed {preprocesser_obj}')\n",
    "            return preprocesser_obj\n",
    "            \n",
    "        except CustomException as e:\n",
    "            logging.info(f'Error cooured {str(e)}')\n",
    "            raise CustomException(sys,e)   \n",
    "\n",
    "\n",
    "    def initiating_data_transformation(self):\n",
    "        try:\n",
    "            train_data=pd.read_csv(self.config.train_data)\n",
    "            test_data=pd.read_csv(self.config.test_data)\n",
    "            \n",
    "\n",
    "            logging.info('data read completed')\n",
    "\n",
    "            Target_col=self.config.target_col\n",
    "           \n",
    "\n",
    "            logging.info('spliting data x_train,y_tran,x_test,y_test')\n",
    "            # x_train\n",
    "            input_feature_train_data=train_data.drop(columns=[Target_col,'Unnamed: 0' ],axis=1)\n",
    "            print(input_feature_train_data.head())\n",
    "\n",
    "            # y_train\n",
    "            target_feature_train_data=train_data[Target_col]\n",
    "            \n",
    "            \n",
    "            #x_test\n",
    "            input_feature_test_data=test_data.drop(columns=[Target_col,'Unnamed: 0' ],axis=1)\n",
    "\n",
    "            #y_test\n",
    "            target_feature_test_data=test_data[Target_col]\n",
    "\n",
    "            preprocesser=self.get_data_transformation_obj()\n",
    "\n",
    "            transform_input_feature_train_data=preprocesser.fit_transform(input_feature_train_data)\n",
    "            transform_input_feature_test_data=preprocesser.transform(input_feature_test_data)\n",
    "\n",
    "            train_arr=np.c_[transform_input_feature_train_data,np.array(target_feature_train_data)]\n",
    "            test_arr=np.c_[transform_input_feature_test_data,np.array(target_feature_test_data)]\n",
    "            \n",
    "            np.save(self.config.train_arr,train_arr)\n",
    "            np.save(self.config.test_arr,test_arr)\n",
    "\n",
    "            save_obj(\n",
    "                file_path=self.config.preproecss_obj,\n",
    "                obj=preprocesser\n",
    "            )\n",
    "\n",
    "            return(\n",
    "                train_arr,\n",
    "                test_arr\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        except CustomException as e:\n",
    "            logging.info(f'Error cooured {str(e)}')\n",
    "            raise CustomException(sys,e)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  carat      cut color clarity  depth  table     x     y     z\n",
      "0  149864   0.90  Premium     I     SI1   63.0   59.0  6.17  6.12  3.90\n",
      "1   28636   1.55  Premium     H     SI1   62.0   58.0  7.37  7.42  4.59\n",
      "2   53148   0.32    Ideal     D     SI1   63.0   55.0  4.38  4.35  2.75\n",
      "3    6925   0.35    Ideal     F     SI1   62.3   57.0  4.53  4.48  2.81\n",
      "4   68453   0.77    Ideal     D     SI1   62.2   56.0  5.85  5.88  3.64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigManager()\n",
    "    data_tranformation_config=config.get_data_transformation_config()\n",
    "    data_tranformation=DataTransformation(config=data_tranformation_config)\n",
    "    data_tranformation.initiating_data_transformation()\n",
    "except Exception as e:\n",
    "            logging.info(f'Error cooured {str(e)}')\n",
    "            raise CustomException(sys,e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
